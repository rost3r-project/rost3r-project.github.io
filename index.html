<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>RoST3R: Robot-Aware Dynamic 3D Reconstruction for Robotic Manipulation</title>
  <link href="./files/style.css" rel="stylesheet">
  <link rel="icon" href="icons/rost3r_icon.png" type="image/png">
  <script type="text/javascript" src="./files/jquery.mlens-1.0.min.js"></script>
  <script type="text/javascript" src="./files/jquery.js"></script>
  <style>
    .divider {
      border-right: 2px dashed #737373;
      width: 2px;
    }
  </style>
  <style>
    .divider_horizontal {
      border-top: 2px dashed #737373;
      display: block;
      width: 100%;
      margin: 10px 0;
    }
  </style>
  <!-- Begin new styles from demos page -->
  <style>
    body {
      padding: 2em;
      font-family: sans-serif;
    }

    iframe {
      border-radius: 0.5em;
      width: 27.5em;
      height: 27.5em;
      border: none;
      box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    @media (max-width: 768px) {
      iframe {
        width: 100%;
        height: 30em;
      }
    }

    a,
    a:link {
      color: #777;
    }

    /* Styles for the instruction icons and text */
    .instructions {
      display: flex;
      justify-content: center;
      align-items: center;
      flex-wrap: wrap;
      gap: 1.2em;
      text-align: center;
      padding: 0.6em;
    }

    .instruction-item {
      display: flex;
      align-items: center;
      gap: 0.5em;
      font-size: 1.2em;
    }

    .instruction-item img {
      width: 36px;
      height: 36px;
    }

    .instructions_small {
      display: flex;
      justify-content: center;
      align-items: center;
      flex-wrap: wrap;
      gap: 1em;
      text-align: center;
      padding: 0.5em;
    }

    .instruction-item_small {
      display: flex;
      align-items: center;
      gap: 0.3em;
      font-size: 1.0em;
    }

    .instruction-item_small img {
      width: 30px;
      height: 30px;
    }

    .video-grid {
  display: grid;
  grid-template-columns: repeat(2, 1fr);
  gap: 20px;
  max-width: 1000px;
  margin: auto;
      background-color: white;
}

.video-grid iframe,
.video-grid video {
  width: 100%;
  aspect-ratio: 12 / 9; /* Enable this to maintain correct aspect ratio */
  height: auto;         /* Ensures the height scales properly */
  object-fit: cover;    /* Ensures the video fills the area (no black borders) */
  display: block;       /* Prevents inline whitespace */
  border: none;         /* Removes default iframe borders */
  border: 2px solid white;   /* white border if any exists */
  background-color: white;   /* fills behind transparent/letterboxed video */
}

    .row {
      display: flex;
      width: 100%;
      height: 60px; /* adjust height as needed */
    }

    .column {
      flex: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      font-size: 20px; /* increase this number as needed */
      font-weight: bold; /* optional: makes text bolder */
      border-right: 1px solid #eee;
    }

    .column:last-child {
      border-right: none; /* remove right border from last column */
    }

    @media (max-width: 768px) {
      .video-grid {
        grid-template-columns: 1fr;
      }
    }
  </style>
  <!-- End new styles -->
</head>

<body>
  <div class="content">
    <h1 style="line-height: 0.75;">
      <img src="./icons/rost3r_icon.png" alt="RoST3R Icon" style="width: 64px; vertical-align: middle;">
      <strong>RoST3R: Robot-Aware Dynamic 3D Reconstruction <br> for Robotic Manipulation</strong>
    </h1>
    <p id="authors">
      <span>
        <a href="https://github.com/Yanbing-Han">Yanbing Han<sup>1*</sup></a>
      </span>
      <span>
        <a href="https://geng-haoran.github.io/">Haoran Geng<sup>2*</sup></a>
      </span>
      <span>
        <a href="https://junyi42.github.io/">Junyi Zhang<sup>2+</sup></a>
      </span>
      <span>
        <a href="https://scholar.google.com/citations?user=u9Z__t0AAAAJ">Ziyu Chen<sup>1</sup></a>
      </span>
      <span>
        <a href="https://charlietcheng.github.io/">Charlie Cheng<sup>2</sup></a>
      </span>
      <br>
      <span>
        <a href="https://github.com/Peihao2021">Peihao Li<sup>2</sup></a>
      </span>
      <span>
        <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel<sup>2</sup></a>
      </span>
      <span>
        <a href="https://people.eecs.berkeley.edu/~trevor/">Trevor Darrell<sup>2</sup></a>
      </span>
      <span>
        <a href="https://people.eecs.berkeley.edu/~malik/">Jitendra Malik<sup>2</sup></a>
      </span>
      <span>
        <a href="https://yuewang.xyz/">Yue Wang<sup>1</sup></a>
      </span>
      <br>
      <span class="institution">
        <sup>1</sup> University of Southern California
        <sup>2</sup> University of California, Berkeley
      </span>
      <br>
      <span class="note">(*: equal contribution, +: project lead)</span>
      <br>
    </p>

    <!-- <br>
        <img src="./files/teaser_monst3r.png" class="teaser-gif" style="width:100%;"><br> -->

    <!-- add video files/teaser_vid_v2_lowres.mp4 -->
    <video width="100%" controls>
      <source src="./files/overview-noborder.mp4" type="video/mp4">
    </video>
    <br>
    <br>

    <a style="text-align:center">
      <font size="+1">
        <strong>RoST3R</strong> reconstructs robot-aware, scale-aligned 3D scene representations directly from RGB images to boost policy learning. It achieves stronger <strong>generalization</strong> compared to policies trained on 2D images.
      </font>
    </a>
    <font size="+2">
      <p style="text-align: center;">
        <a href="files\monst3r_paper.pdf" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://arxiv.org/abs/2410.03825" target="_blank">[Arxiv]</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="page1.html" target="_blank" style="font-weight: bold; color: rgb(238, 60, 223);">[Interactive ResultsðŸ”¥]</a> &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank">[Code]</a>&nbsp;&nbsp;&nbsp;&nbsp;
        <!-- <a href="https://x.com/junyi42/status/1770799360353145037" target="_blank">[Twitter Post]</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
        <!-- <a href="https://www.youtube.com/watch?v=fyhg50qlNW8" target="_blank">[Video]</a>&nbsp;&nbsp;&nbsp;&nbsp; -->
        <a href="files/bibtex.txt" target="_blank">[BibTeX]</a>
      </p>
    </font>
  </div>

  <!-- Begin new content: Demos -->
<div class="content">
    <h2>Interactive 4D Visualization</h2>
    <p>Explore the 4D reconstruction results of MonST3R on various dynamic scenes. For more results, please visit the <a href="page1.html" style="font-weight: bold; color: rgb(238, 60, 223);">interactive results</a>.</p>
  <!-- Instructions with icons -->
  <div class="instructions" style="margin-top: -1em;">
    <div class="instruction-item" style="display: flex; align-items: center;">
      <img src="icons/left-click.png" alt="Left Click" style="margin-right: 0px;">
      <span>Drag with <em>left</em> click to <strong>rotate</strong> view</span>
    </div>

    <div class="instruction-item" style="display: flex; align-items: center; margin-top: 10px;">
      <img src="icons/scroll-wheel.png" alt="Scroll Wheel" style="margin-right: -5px;">
      <span>Scroll to <strong>zoom</strong> in/out</span>
    </div>

    <div class="instruction-item" style="display: flex; align-items: center; margin-top: 10px;">
      <img src="icons/right-click.png" alt="Right Click" style="margin-right: 0px;">
      <span>Drag with <em>right</em> click to <strong>move</strong> view</span>
    </div>
  </div>

  <div class="instructions_small">
    <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
      <img src="icons/letter-w.png" alt="W" style="margin-right: -10px;">
      <img src="icons/letter-s.png" alt="S" style="margin-right: 0px;">
      <span>Moving forward and backward</span>
    </div>

    <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
      <img src="icons/letter-a.png" alt="A" style="margin-right: -10px;">
      <img src="icons/letter-d.png" alt="D" style="margin-right: 0px;">
      <span>Moving left and right</span>
    </div>

    <div class="instruction-item_small" style="display: flex; align-items: center; margin-top: -15px;">
      <img src="icons/letter-q.png" alt="Q" style="margin-right: -10px;">
      <img src="icons/letter-e.png" alt="E" style="margin-right: 0px;">
      <span>Moving upward and downward</span>
    </div>
  </div>

  <!-- Downsampling note -->
  <p style="text-align: center; font-size: 1em; padding: 0em; color: #555;">
    (Results are downsampled <strong>4 times</strong> for efficient online rendering)
  </p>

  <!-- Wrapper for iframes -->
  <div id="wrapper" style="
        display: flex;
        flex-wrap: wrap;
        justify-content: center;
        align-items: center;
        gap: 2em;
      ">
    <!-- Insert two iframes -->
    <iframe
      src="https://rost3r-project.github.io//build/?playbackPath=https://rost3r-project.github.io/recordings/recording_demo_0025.viser&initDistanceScale=1&initHeightOffset=0.0"></iframe>

    <iframe
      src="https://rost3r-project.github.io//build/?playbackPath=https://rost3r-project.github.io/recordings/recording_bear.viser&initDistanceScale=0.2&initHeightOffset=0.175"></iframe>
  </div>

  </div>

  <!-- End new content -->

  <div class="content">
    <h2 style="text-align:center;">Abstract</h2>
    <font size="-0.">
    <p>Three-dimensional scene representations offer stronger generalization
for policy learning compared to two-dimensional representations, yet collecting
such 3D data has required special sensors. Previous methods for 3D reconstruc-
tion from video exist, but have been unsuitable for robotic learning due to error and
lack of metric calibration. In this work, we demonstrate that 3D scene representa-
tions can be reliably reconstructed from standard 2D RGB images, making it both
accessible and practical for robot learning. We propose a novel framework that
incrementally reconstructs dynamic 3D scenes at metric scale from RGB images,
enabling 3D-aware policy learning in complex environments from only 2D inputs.
At its core, our approach estimates the robotâ€™s pose during scene reconstruction,
registers its kinematic structure within the environment, and builds a unified 3D
scene representation. This unified 3D representation offers two key benefits: it
enables policy learning at metric scale in a consistent world frameâ€”decoupling
object and camera dynamicsâ€”and provides a coherent model of the robot and
environment to support fine-grained spatial reasoning. Notably, while the input
remains 2D, our approach generates a 3D-aware representation that significantly
improves generalization. Experiments show that policies trained with this 3D rep-
resentation outperform those trained on 2D inputs, particularly in tasks involving
environmental variations, novel viewpoints and camera motion. In simulation,
our method outperforms 2D counterparts by 24.5% under environmental variations and dynamic camera motion. In real-world scenarios, it achieves a 40.0%
performance improvement.
    </p>
  </font>
  </div>
  
  <div class="content">
    <h2>Robot-Aware Scale-Aligned Dynamic 3D Reconstruction</h2>
    <img class="summary-img" src="./files/CoRL-overview11.png" style="width:100%;">
    <a>
      RoST3R extends MonST3R for incremental dynamic 3D reconstruc-
tion in the world coordinate, by adjusting the pair-sampling strategy for a global streaming pointmap
optimization (Sec 3.1). Then, by aligning the robot 3D model with 2D observations in each frame
(Sec 3.2), RoST3R can reliably register the robot into the environment in a unified 3D space, as well
as calibrate the environment reconstruction to be metric-scale (Sec 3.3).
    </a>

    <!-- <p> The global optimization is based on the following three loss terms: </p>
    <ul>
      <li> <strong>Alignment loss</strong>: align the global point cloud of each frame with every pairwise pointmap. </li>
      <li> <strong>Flow loss</strong>: encourage the projected flow from global pointmaps and camera poses to be consitent with the estimated flow. </li>
      <li> <strong>Smoothness loss</strong>: enforce the temporal smoothness of camera trajectory. </li>
    </ul> -->
  </div>

  <div class="content">
    <h2>Results - Robot Pose Estimation</h2>
    <p> <strong>Quantitatively</strong> our framework accurately estimates robot pose in real-world scenarios (Panda 3CAM) and under partial occlusion conditions (RoboVerse).
    In each image, the robot mesh is projected onto the image using the pose estimated by our method.</p>
    <img class="summary-img" src="./files/figure_grid_with_pretty_labels.png" style="width:80%;">
    <div class="column">Visualization of pose estimation</div>
    <!-- todo, video depth example from davis -->
  </div>

  <div class="content">
    <h2>Results - RoboVerse</h2>
    <p> <strong>Quantitatively</strong>, out RoST3R 3D representation demonstrates superior generalization ability compared to its 2D-based counterparts. </p>
    <img class="summary-img" src="./files/robovese.jpg" style="width:80%;">
    <div class="column">Generalization levels of evaluation on RoboVerse benchmark</div>
  </div>

  <div class="content">
    <h2>Results - Real World</h2>
    <p> Qualitative comparison of real-world task executions using <strong>Diffusion Policy (Left)</strong> and <strong>RoST3R-DP3 (Right)</strong>.  </p>
    <div class="video-grid">
    <iframe src="./files/plant_dp.mp4" allowfullscreen></iframe>
    <iframe src="./files/plant_rost3r.mp4" allowfullscreen></iframe>
    <iframe src="./files/rose_dp.mp4" allowfullscreen></iframe>
    <iframe src="./files/rose_plant.mp4" allowfullscreen></iframe>
    <iframe src="./files/water_dp.mp4" allowfullscreen></iframe>
    <iframe src="./files/water_rost3r.mp4" allowfullscreen></iframe>
    </div>
    <div class="row">
      <div class="column">DP</div>
      <div class="column">RoST3R-DP3</div>
    </div>
    <p> <strong>Quantitatively</strong>, Our method outperforms 2D-based Diffusion Policy, highlighting the importance of 3D reasoning capabilities. </p>
    <img class="summary-img" src="./files/real-score.jpg" style="width:80%;">
  </div>


  </div>

  <div class="content">
    <h2>BibTex</h2>
    <font size="-0.">
    <code> @article{yanbing2025rost3r,<br>
    &nbsp;&nbsp;title={RoST3R: Robot-Aware Dynamic 3D Reconstruction for Robotic Manipulation},<br>
    &nbsp;&nbsp;author={Han, Yanbing and Geng, Haoran and Zhang, Junyi and Chen, Ziyu and Cheng, Charlie and Li, Peihao and Abbeel, Pieter and Darell, Trevor and Wang, Yue},<br>
    &nbsp;&nbsp;journal={arXiv preprint arxiv:???},<br>
    &nbsp;&nbsp;year={2024}<br>
    } </code>
  </font>
  </div>
  
  <div class="content" id="acknowledgements">
    <p><strong>Acknowledgements</strong>:
      We borrow this template from <a href="https://monst3r-project.github.io/">MonST3R</a>, which is originally from <a href="https://dreambooth.github.io/">DreamBooth</a>.
      The interactive 4D visualization is powered by <a href="https://github.com/nerfstudio-project/viser">Viser</a>.
      We sincerely thank <a href="https://scholar.google.com/citations?hl=en&user=Ecy6lXwAAAAJ">Brent Yi</a> for his support in setting up the online visualization.
    </p>
  </div>
</body>

</html>
